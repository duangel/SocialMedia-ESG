{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UnMILk1I-0jT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697984085686,"user_tz":-120,"elapsed":2275,"user":{"displayName":"Angela Du","userId":"17293833042315140000"}},"outputId":"eace4770-bc3e-47ae-95a6-852c05a36a0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Master Thesis\n","candidate_sentences.csv               \u001b[0m\u001b[01;34mdata\u001b[0m/                            PreProcessing.ipynb\n","candidate_sentences_pred_CLUSTER.csv  dataAnalysis.ipynb               sentimentAggregation.ipynb\n","candidate_sentences_pred.csv          FindCandidates_V2_onlyESG.ipynb  SP500.ipynb\n","\u001b[01;34mCB_sentence\u001b[0m/                          \u001b[01;34mfull_gov\u001b[0m/\n","ClassificationPipeline_AD.ipynb       \u001b[01;34mfull_soc\u001b[0m/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Master Thesis\n","%ls"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","path = './data/ESG'\n","bbgNames = os.listdir('./data/Results')"],"metadata":{"id":"yyx6Bj0--4VX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get Refinitiv ESG Scores"],"metadata":{"id":"gWwV36xjthhe"}},{"cell_type":"code","source":["scoresRefiv = {}\n","xls = pd.ExcelFile(path + '/RefinitivESG.xlsx')\n","\n","for s in xls.sheet_names:\n","  scoresRefiv[s] = xls.parse(s).iloc[:,1:]\n","\n","names = scoresRefiv['2021']['Company Common Name'].tolist()\n","mismatchedNames = []\n","sameNames = pd.DataFrame(columns=['Refinitiv','BBG'])\n","cols = scoresRefiv['2021'].columns[1:]\n","comps = {}\n","for n in names:\n","  df = pd.DataFrame(index = ['2021','2020','2019','2018','2017','2016'], columns = cols)\n","  for k,v in scoresRefiv.items():\n","    try:\n","      df.loc[[k],:] = v[v['Company Common Name']==n].iloc[:,1:].values[0]\n","    except:\n","      continue\n","  comps[n] = df\n","\n","  if n.upper() in bbgNames:\n","    #sameNames = sameNames.append(pd.DataFrame([n,n.upper()]).T.rename(columns = {0:'Refinitiv',1:'BBG'}))\n","    sameNames = pd.concat([sameNames,pd.DataFrame([n,n.upper()]).T.rename(columns = {0:'Refinitiv',1:'BBG'})])\n","  else:\n","    mismatchedNames.append(n)\n","\n","  '''\n","  try:\n","    df.to_csv('./data/Results/%s/esgRefinitiv.csv'%(n.upper()))\n","  except:\n","    mismatchedNames.append(n)\n","  '''"],"metadata":{"id":"Nfii5iL7tg6c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some names from Refinitiv mismatch with Bloomberg. I manually verify and re-match to save the Refinitiv data in the right folders (only need to run once)"],"metadata":{"id":"oM-6Lh2ZsJ61"}},{"cell_type":"code","source":["mismatchedNames = pd.read_csv('./data/ESG/names.csv').dropna()\n","mismatchedNamesDict = mismatchedNames.set_index('Refinitiv').to_dict()['BBG']\n","\n","for k,v in mismatchedNamesDict.items():\n","  ref = k\n","  bbg = v\n","  comps[k].to_csv('./data/Results/%s/esgRefinitiv.csv'%v)"],"metadata":{"id":"S4uW6ddDsHxo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#RepRisk data to folders\n","---"],"metadata":{"id":"M6oQTHUEeABo"}},{"cell_type":"markdown","source":["Get RepRisk Company name equivalent in BBG"],"metadata":{"id":"KKdKKgEasTgO"}},{"cell_type":"code","source":["allCompNames = pd.read_csv('./data/ESG/names.csv').dropna()\n","allCompNames = pd.concat([allCompNames,sameNames])\n","allCompNames.sort_values(by=['BBG'], inplace=True)\n","allCompNames['isin'] = [0]*len(allCompNames)\n","\n","isin = pd.read_excel('./data/ESG/sp500_isin.xlsx').drop(columns=['Unnamed: 0']).set_index('Company Common Name')\n","isinDict = isin.to_dict()['ISIN']\n","\n","nope = []\n","for i in range(len(allCompNames)):\n","  name = allCompNames.iloc[i,0]\n","  try:\n","    allCompNames.iloc[i,2] = isinDict[name]\n","  except:\n","    nope.append(name)\n","\n","#allCompNames.set_index('isin',inplace=True)\n","allCompNames"],"metadata":{"id":"Q8M1yo-8nI6G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Add reprisk names by isin (run once)\n","currently, the only manual changes made were to add Advance Auto Parts, Alphabet Inc, Fox Corp, News Corp, DXC Technologies, Linde PLC, Newell Brands . All others do not exist in RepRisk"],"metadata":{"id":"JLssf-06v6kv"}},{"cell_type":"code","source":["repNames = pd.read_csv('./data/ESG/2022.csv')[['company_name','primary_isin']].set_index('primary_isin')\n","repNamesU = repNames.drop_duplicates()\n","allCompNames['RepRisk'] = [np.nan]*len(allCompNames)\n","nameDict = repNamesU.to_dict()['company_name']\n","\n","nopeRep = []\n","for i in range(len(allCompNames)):\n","  isin = allCompNames.index[i]\n","  try:\n","    allCompNames.iloc[i,2] = nameDict[isin]\n","  except:\n","    nopeRep.append(isin)\n","#allCompNames[allCompNames.isna().any(axis=1)] #get names of companies that were not found in RepRisk --> manually check\n","\n","allCompNames.to_csv('./data/ESG/allNamesFromProviders.csv')"],"metadata":{"id":"7Y9L4Ifcuiwn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save RepRisk Scores to corresponding folders\n"],"metadata":{"id":"ksDp5AmKsk48"}},{"cell_type":"code","source":["def saveScoresToCompByYears(yearsDf,namesDict,sortby='date',toSave=False):\n","  comps = {}\n","  for m,n in namesDict.items():\n","    print('--- Starting for %s ---'%m)\n","\n","    comps[m] = yearsDf[yearsDf['company_name']==n].sort_values(sortby).reset_index().drop(columns=['index','company_name','primary_isin'])\n","    comps[m]['current_rriDiff'] = comps[m]['current_rri'].diff()\n","\n","    if toSave:\n","      comps[m].iloc[1:,:].to_csv('./data/Results/%s/RepRiskRRI.csv'%m)\n","\n","    print('--- Done for %s ---'%m)\n","\n","  return comps"],"metadata":{"id":"JXyQERhp2PmW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def saveScoresToCompByYears(yearsDf,namesDict,valuesDict=None,sortby='date',toSave=False):\n","  comps = {}\n","  for m,n in namesDict.items():\n","    print('--- Starting for %s ---'%m)\n","\n","    comps[m] = yearsDf[yearsDf['company_name']==n].sort_values(sortby).reset_index().drop(columns=['index','company_name','primary_isin'])\n","\n","    df = comps[m].copy()\n","\n","    if valuesDict == None:\n","      comps[m]['current_rriDiff'] = comps[m]['current_rri'].diff()\n","      if toSave:\n","        comps[m].iloc[1:,:].to_csv('./data/Results/%s/RepRiskRRI.csv'%m)\n","\n","    else:\n","      c = []\n","      for r in df['reprisk_rating'].values.tolist():\n","        c.append(valuesDict[r])\n","\n","      df['rating'] = c\n","      df['ratingchange'] = df['rating'].diff()\n","      if toSave:\n","        df.iloc[1:,:].to_csv('./data/Results/%s/RepRiskRating.csv'%m)\n","\n","    print('--- Done for %s ---'%m)\n","\n","  #return comps"],"metadata":{"id":"vTxTOs2VIQrd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Give numerical values to RepRisk Ratings"],"metadata":{"id":"qS3zjvFqd02f"}},{"cell_type":"code","source":["years = list(range(2015,2023))\n","credit_ratings = {\n","    \"AAA\": 10,\n","    \"AA\": 9,\n","    \"A\": 8,\n","    \"BBB\": 7,\n","    \"BB\": 6,\n","    \"B\": 5,\n","    \"CCC\": 4,\n","    \"CC\": 3,\n","    \"C\": 2,\n","    \"D\": 1\n","}\n","\n","cnt=0\n","for y in years:\n","  if cnt==0:\n","    scoresRRI = pd.read_csv(path + '/RepRisk/%s.csv'%y)\n","  else:\n","    scoresRRI = pd.concat([scoresRRI,pd.read_csv(path + '/RepRisk/%s.csv'%y)])\n","  cnt+=1\n","\n","namesDict = pd.read_csv(path + '/allNamesFromProviders.csv')[['BBG','RepRisk']].dropna().set_index('BBG').to_dict()['RepRisk']\n","saveScoresToCompByYears(scoresRRI,namesDict,None, sortby='date',toSave=False)\n","saveScoresToCompByYears(scoresRRI,namesDict,credit_ratings, sortby='date',toSave=True)\n","\n"],"metadata":{"id":"gmIMMzLM1KsB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["manually save for Advance Auto Parts Inc. (run once)"],"metadata":{"id":"XsiPq4ecedYh"}},{"cell_type":"code","source":["years = list(range(2015,2023))\n","cnt=0\n","for y in years:\n","  if cnt==0:\n","    scoresRRIAAP = pd.read_csv(path + '/RepRisk/%s_AAP.csv'%y)\n","  else:\n","    scoresRRIAAP = pd.concat([scoresRRIAAP,pd.read_csv(path + '/RepRisk/%s_AAP.csv'%y)])\n","  cnt+=1\n","\n","scoresRRIAAP = scoresRRIAAP.sort_values('date').reset_index().drop(columns=['index','company_name','primary_isin'])\n","df = scoresRRIAAP.copy()\n","\n","scoresRRIAAP['current_rriDiff'] = scoresRRIAAP['current_rri'].diff()\n","scoresRRIAAP.iloc[1:,:].to_csv('./data/Results/ADVANCE AUTO PARTS INC/RepRiskRRI.csv')\n","\n","\n","c = []\n","for r in df['reprisk_rating'].values.tolist():\n","  c.append(credit_ratings[r])\n","\n","df['rating'] = c\n","df['ratingchange'] = df['rating'].diff()\n","df.iloc[1:,:].to_csv('./data/Results/ADVANCE AUTO PARTS INC/RepRiskRating.csv')"],"metadata":{"id":"yffepWxhrvb6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["manually save for DXC, Linde and Newell. (run once)"],"metadata":{"id":"J12Ayl4ieZF0"}},{"cell_type":"code","source":["years = list(range(2015,2023))\n","\n","cnt=0\n","for y in years:\n","  if cnt==0:\n","    scoresRRI = pd.read_csv(path + '/RepRisk/%s_stragglers.csv'%y)\n","  else:\n","    scoresRRI = pd.concat([scoresRRI,pd.read_csv(path + '/RepRisk/%s_stragglers.csv'%y)])\n","  cnt+=1\n","\n","namesDict = {'DXC TECHNOLOGY CO':'DXC Technology Co (formerly Everett SpinCo Inc)', 'LINDE PLC':'Linde PLC','NEWELL BRANDS INC':'Newell Brands Inc (formerly Newell Rubbermaid Inc)'}\n","saveScoresToCompByYears(scoresRRI,namesDict,credit_ratings, sortby='date',toSave=True)\n","saveScoresToCompByYears(scoresRRI,namesDict,None, sortby='date',toSave=True)\n"],"metadata":{"id":"_FdPOvPZoOE5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Save Bloomberg ESG Scores to corresponding folders + get score changes\n","---"],"metadata":{"id":"mCa5A8t1prUS"}},{"cell_type":"code","source":["scoretemp = pd.read_csv(path + '/SP500_ESGScores.csv', index_col=0).iloc[2:,:]\n","df = pd.read_csv(path + '/SP500_Names.csv')\n","scoretemp.columns = scoretemp.iloc[0,:]\n","sp500 = scoretemp.iloc[3:,:]\n","sp500 = sp500.astype('float')\n","\n","temp = pd.DataFrame(np.array(df.columns).reshape((1,2)), columns = ['Ticker', 'CompanyName'])\n","df.columns = ['Ticker', 'CompanyName']\n","sp500Names = temp.append(df)\n","\n","for c in sp500Names.CompanyName:\n","#  if os.path.exists(\"./data/Results/%s\"%c)==False:\n","#    os.mkdir(\"./data/Results/%s\"%c)\n","\n","  ticker = sp500Names[sp500Names['CompanyName']=='%s'%c].Ticker.tolist()[0]\n","\n","  tickerLoc = sp500.columns.get_loc('%s'%ticker)\n","  esg = sp500.iloc[:,tickerLoc : tickerLoc+4].dropna(how='all')\n","  esg.columns = ['Social', 'Gov', 'Env', 'ESG']\n","  esg[['SocialDiff', 'GovDiff', 'EnvDiff', 'ESGDiff']] = esg.diff()\n","\n","  esg.iloc[1:,:].to_csv(\"./data/Results/%s/esg.csv\"%c)\n","\n","  print('Done with %s'%c)"],"metadata":{"id":"DXLiol68G5ev"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save Classification to respective companies"],"metadata":{"id":"jYqzqpu_xio2"}},{"cell_type":"code","source":["esgPath = './ESG'\n","rrClasses = pd.read_csv(esgPath+'/RepRisk/repriskClass.csv')\n","namesDict = pd.read_csv(esgPath + '/allNamesFromProviders.csv')[['BBG','RepRisk']].dropna().set_index('BBG').to_dict()['RepRisk']\n","uniqueComps = rrClasses.company_name.unique().tolist()\n","noRiskIncidentsComps = []\n","\n","\n","for m,n in tqdm(namesDict.items()):\n","  print('--- Starting for %s ---'%m)\n","\n","  if n not in uniqueComps:\n","    noRiskIncidentsComps.append(m)\n","    continue\n","\n","  df = rrClasses[rrClasses['company_name']==n].sort_values('incident_date').reset_index().drop(columns=['reprisk_id','index','company_name','primary_isin'])\n","  df.to_csv('./Results/%s/repriskClasses.csv'%m)\n","\n","  print('--- Done for %s ---'%m)"],"metadata":{"id":"Ehqo9W0uuGWB"},"execution_count":null,"outputs":[]}]}